{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c058f870",
   "metadata": {},
   "source": [
    "# NLP Feedback Modeling Framework (NLP + Survey Analytics)\n",
    "**Autor:** David José Parales Araujo  \n",
    "**Objetivo:** Framework replicable para clasificar feedback textual (binario y multiclase) e integrar analítica de encuestas (Likert) para construir un **Índice de Desempeño 0–100**.  \n",
    "**Aplicaciones:** Educación (alumno→docente / directivo→docente / autoevaluación), HR Analytics, Customer Feedback, Calidad de servicio.\n",
    "\n",
    "> Este notebook usa un dataset **sintético** para demostración. Reemplázalo por tu dataset real anonimizado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2a01ce",
   "metadata": {},
   "source": [
    "## 1) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4787c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si ejecutas en Colab, descomenta estas líneas.\n",
    "# !pip -q install pandas numpy scikit-learn nltk matplotlib joblib imbalanced-learn\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, ConfusionMatrixDisplay,\n",
    "    f1_score\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NLP utils\n",
    "import nltk\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "nltk.download(\"stopwords\", quiet=True)\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Opcional (solo si quieres SMOTE)\n",
    "try:\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    IMBLEARN_AVAILABLE = True\n",
    "except Exception:\n",
    "    IMBLEARN_AVAILABLE = False\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02d07da",
   "metadata": {},
   "source": [
    "## 2) Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277b1357",
   "metadata": {},
   "source": [
    "### Escenarios soportados\n",
    "1. **Binario:** `risk` vs `ok`.\n",
    "2. **Multiclase:** `Negativa / Neutral / Positiva`.\n",
    "3. **Score continuo:** **Índice 0–100** (derivado de Likert + señales del texto).\n",
    "\n",
    "### Nota de diseño (importante)\n",
    "- **Las etiquetas NO deben salir del mismo texto con reglas ad-hoc** si vas a entrenar un modelo supervisado (riesgo de leakage).\n",
    "- En este framework, la etiqueta se puede derivar de **encuesta estructurada** (Likert) y el texto se usa como predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd42ebb0",
   "metadata": {},
   "source": [
    "## 3) Data Model (schema recomendado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53fc98a",
   "metadata": {},
   "source": [
    "Columnas recomendadas (mínimo viable):\n",
    "\n",
    "- `source`: student / leadership / self  \n",
    "- `year`: año  \n",
    "- `level`: curso/año (ej: 5)  \n",
    "- `role_evaluator`: student / director / self  \n",
    "- `likert_avg`: promedio Likert normalizado **0–1**  \n",
    "- `text_feedback`: comentario libre\n",
    "\n",
    "Targets derivados:\n",
    "- `performance_index` (0–100)\n",
    "- `target_binary` (0/1)\n",
    "- `target_multiclass` (Negativa/Neutral/Positiva)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edc7cf6",
   "metadata": {},
   "source": [
    "## 4) Build a Synthetic Dataset (demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bd1f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_texts = [\n",
    "    \"Explica con claridad y responde dudas con paciencia.\",\n",
    "    \"Las clases son dinámicas y se nota dominio del tema.\",\n",
    "    \"Motiva al curso y brinda material útil.\",\n",
    "    \"Evalúa de forma justa y retroalimenta con detalle.\"\n",
    "]\n",
    "\n",
    "neutral_texts = [\n",
    "    \"Algunas clases son buenas, otras podrían mejorar.\",\n",
    "    \"A veces explica claro, a veces rápido.\",\n",
    "    \"El ritmo es variable, en general cumple.\"\n",
    "]\n",
    "\n",
    "negative_texts = [\n",
    "    \"Las explicaciones son confusas y desorganizadas.\",\n",
    "    \"No responde bien a las preguntas y llega tarde.\",\n",
    "    \"Las clases son aburridas y poco productivas.\",\n",
    "    \"Las evaluaciones no reflejan lo visto en clase.\"\n",
    "]\n",
    "\n",
    "def make_rows(n=600, p_pos=0.65, p_neu=0.20, p_neg=0.15):\n",
    "    rows = []\n",
    "    for _ in range(n):\n",
    "        r = np.random.rand()\n",
    "        if r < p_neg:\n",
    "            txt = np.random.choice(negative_texts)\n",
    "            likert = np.random.uniform(0.15, 0.55)\n",
    "        elif r < p_neg + p_neu:\n",
    "            txt = np.random.choice(neutral_texts)\n",
    "            likert = np.random.uniform(0.45, 0.75)\n",
    "        else:\n",
    "            txt = np.random.choice(positive_texts)\n",
    "            likert = np.random.uniform(0.65, 0.95)\n",
    "\n",
    "        source = np.random.choice([\"student\", \"leadership\", \"self\"], p=[0.7, 0.2, 0.1])\n",
    "        role = {\"student\":\"student\", \"leadership\":\"director\", \"self\":\"self\"}[source]\n",
    "        year = np.random.choice([2023, 2024, 2025])\n",
    "        level = np.random.choice([1,2,3,4,5])\n",
    "\n",
    "        rows.append([source, year, level, role, float(likert), txt])\n",
    "    return pd.DataFrame(rows, columns=[\"source\",\"year\",\"level\",\"role_evaluator\",\"likert_avg\",\"text_feedback\"])\n",
    "\n",
    "df = make_rows(n=900)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8030c0",
   "metadata": {},
   "source": [
    "## 5) Preprocessing Pipeline (Spanish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1f2840",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS_ES = set(stopwords.words(\"spanish\"))\n",
    "\n",
    "def preprocess_text(text: str) -> str:\n",
    "    text = (text or \"\").lower()\n",
    "    text = re.sub(r\"[^a-záéíóúñü\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    tokens = word_tokenize(text, language=\"spanish\")\n",
    "    tokens = [t for t in tokens if t not in STOPWORDS_ES and len(t) > 2]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df[\"text_clean\"] = df[\"text_feedback\"].apply(preprocess_text)\n",
    "df[[\"text_feedback\",\"text_clean\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9186117",
   "metadata": {},
   "source": [
    "## 6) Survey Analytics → Performance Index (0–100) + Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5e6b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"performance_index\"] = (df[\"likert_avg\"] * 100).round().astype(int)\n",
    "\n",
    "def multiclass_from_index(idx: int) -> str:\n",
    "    if idx < 50:\n",
    "        return \"Negativa\"\n",
    "    if idx <= 75:\n",
    "        return \"Neutral\"\n",
    "    return \"Positiva\"\n",
    "\n",
    "df[\"target_multiclass\"] = df[\"performance_index\"].apply(multiclass_from_index)\n",
    "df[\"target_binary\"] = (df[\"performance_index\"] >= 60).astype(int)  # 1 = OK, 0 = Risk\n",
    "\n",
    "df[[\"likert_avg\",\"performance_index\",\"target_binary\",\"target_multiclass\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3731d7e3",
   "metadata": {},
   "source": [
    "## 7) Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5da62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"text_clean\"].values\n",
    "y_bin = df[\"target_binary\"].values\n",
    "y_multi = df[\"target_multiclass\"].values\n",
    "\n",
    "X_train, X_test, yb_train, yb_test = train_test_split(\n",
    "    X, y_bin, test_size=0.2, random_state=SEED, stratify=y_bin\n",
    ")\n",
    "\n",
    "Xm_train, Xm_test, ym_train, ym_test = train_test_split(\n",
    "    X, y_multi, test_size=0.2, random_state=SEED, stratify=y_multi\n",
    ")\n",
    "\n",
    "print(\"Binary class distribution:\", np.bincount(yb_train), \"train |\", np.bincount(yb_test), \"test\")\n",
    "print(\"Multiclass distribution:\\n\", pd.Series(ym_train).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09027898",
   "metadata": {},
   "source": [
    "## 8) Baselines: TF-IDF + Logistic Regression / Linear SVM (Binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9888c2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_lr = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(ngram_range=(1,2), max_features=5000)),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000, class_weight=\"balanced\", random_state=SEED))\n",
    "])\n",
    "\n",
    "binary_svm = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(ngram_range=(1,2), max_features=5000)),\n",
    "    (\"clf\", LinearSVC(class_weight=\"balanced\", random_state=SEED))\n",
    "])\n",
    "\n",
    "binary_lr.fit(X_train, yb_train)\n",
    "pred_lr = binary_lr.predict(X_test)\n",
    "\n",
    "binary_svm.fit(X_train, yb_train)\n",
    "pred_svm = binary_svm.predict(X_test)\n",
    "\n",
    "print(\"=== Logistic Regression (Binary) ===\")\n",
    "print(classification_report(yb_test, pred_lr, target_names=[\"risk(0)\",\"ok(1)\"]))\n",
    "\n",
    "print(\"=== Linear SVM (Binary) ===\")\n",
    "print(classification_report(yb_test, pred_svm, target_names=[\"risk(0)\",\"ok(1)\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c213e57d",
   "metadata": {},
   "source": [
    "### Confusion Matrix (Binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bc8abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,4))\n",
    "ConfusionMatrixDisplay.from_predictions(yb_test, pred_lr, display_labels=[\"risk\",\"ok\"], ax=ax)\n",
    "ax.set_title(\"Binary - Logistic Regression\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a596165",
   "metadata": {},
   "source": [
    "## 9) Cross-Validation (Binary) — Macro F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bf7b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "scores = cross_val_score(binary_lr, X, y_bin, cv=cv, scoring=\"f1_macro\")\n",
    "print(\"Macro F1 (5-fold):\", round(scores.mean(), 4), \"+/-\", round(scores.std(), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a0c9b4",
   "metadata": {},
   "source": [
    "## 10) Threshold Tuning (Binary) — usando probabilidades (LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7847ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = binary_lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "thresholds = np.linspace(0.2, 0.8, 13)\n",
    "best_thr, best_f1 = None, -1\n",
    "\n",
    "for thr in thresholds:\n",
    "    pred_thr = (proba >= thr).astype(int)\n",
    "    f1 = f1_score(yb_test, pred_thr, average=\"macro\")\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_thr = float(thr)\n",
    "\n",
    "print(\"Best threshold:\", best_thr, \"Macro F1:\", round(best_f1, 4))\n",
    "pred_best = (proba >= best_thr).astype(int)\n",
    "print(classification_report(yb_test, pred_best, target_names=[\"risk(0)\",\"ok(1)\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22834c01",
   "metadata": {},
   "source": [
    "## 11) Multiclass Modeling (Negativa / Neutral / Positiva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec61117",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_lr = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(ngram_range=(1,2), max_features=8000)),\n",
    "    (\"clf\", LogisticRegression(max_iter=3000, class_weight=\"balanced\", random_state=SEED))\n",
    "])\n",
    "\n",
    "multi_lr.fit(Xm_train, ym_train)\n",
    "pred_m = multi_lr.predict(Xm_test)\n",
    "\n",
    "print(classification_report(ym_test, pred_m))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b71f66d",
   "metadata": {},
   "source": [
    "### Confusion Matrix (Multiclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911c23d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "ConfusionMatrixDisplay.from_predictions(ym_test, pred_m, ax=ax, xticks_rotation=45)\n",
    "ax.set_title(\"Multiclass - Logistic Regression\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6e8eec",
   "metadata": {},
   "source": [
    "## 12) Imbalance Handling (Opcional): SMOTE (requiere imbalanced-learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8226be",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IMBLEARN_AVAILABLE:\n",
    "    vec = TfidfVectorizer(ngram_range=(1,2), max_features=5000)\n",
    "    Xv = vec.fit_transform(X_train)\n",
    "    sm = SMOTE(random_state=SEED)\n",
    "    X_res, y_res = sm.fit_resample(Xv, yb_train)\n",
    "    clf = LogisticRegression(max_iter=2000, random_state=SEED)\n",
    "    clf.fit(X_res, y_res)\n",
    "    Xt = vec.transform(X_test)\n",
    "    pred = clf.predict(Xt)\n",
    "    print(classification_report(yb_test, pred, target_names=[\"risk(0)\",\"ok(1)\"]))\n",
    "else:\n",
    "    print(\"SMOTE no disponible. Instala con: pip install imbalanced-learn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a17357",
   "metadata": {},
   "source": [
    "## 13) Composite Performance Index (0–100) — Integración Survey + NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2813a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_ok_text = binary_lr.predict_proba(df[\"text_clean\"])[:, 1]\n",
    "score_likert = df[\"likert_avg\"].values  # 0-1\n",
    "\n",
    "score_comp = (0.6 * score_likert + 0.4 * prob_ok_text) * 100\n",
    "df[\"performance_index_composite\"] = score_comp.round().astype(int)\n",
    "\n",
    "df[[\"performance_index\",\"performance_index_composite\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7327614d",
   "metadata": {},
   "source": [
    "## 14) Aggregations — listo para Power BI / Looker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9627bfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = (df\n",
    "       .groupby([\"year\",\"level\",\"role_evaluator\"], as_index=False)\n",
    "       .agg(\n",
    "           n=(\"text_feedback\",\"count\"),\n",
    "           index_mean=(\"performance_index_composite\",\"mean\"),\n",
    "           index_p25=(\"performance_index_composite\", lambda x: np.percentile(x, 25)),\n",
    "           index_p75=(\"performance_index_composite\", lambda x: np.percentile(x, 75)),\n",
    "       ))\n",
    "agg.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536e010c",
   "metadata": {},
   "source": [
    "## 15) Ethical & Interpretability Considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4365035e",
   "metadata": {},
   "source": [
    "- No subir feedback real en repos públicos sin anonimización y permiso.\n",
    "- Revisiones humanas para casos borderline.\n",
    "- Para interpretabilidad: inspeccionar tokens con mayor peso en modelos lineales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d830c167",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = binary_lr.named_steps[\"tfidf\"]\n",
    "clf = binary_lr.named_steps[\"clf\"]\n",
    "\n",
    "feature_names = np.array(tfidf.get_feature_names_out())\n",
    "coefs = clf.coef_.ravel()\n",
    "\n",
    "top_ok = feature_names[np.argsort(coefs)[-15:]][::-1]\n",
    "top_risk = feature_names[np.argsort(coefs)[:15]]\n",
    "\n",
    "print(\"Top tokens que empujan a OK (1):\\n\", top_ok)\n",
    "print(\"\\nTop tokens que empujan a RISK (0):\\n\", top_risk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8233cc",
   "metadata": {},
   "source": [
    "## 16) How to plug your real data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b6ff66",
   "metadata": {},
   "source": [
    "CSV mínimo recomendado:\n",
    "\n",
    "`source,year,level,role_evaluator,likert_avg,text_feedback`\n",
    "\n",
    "✅ Este notebook ya es demostrable, replicable y orientado a industria."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}