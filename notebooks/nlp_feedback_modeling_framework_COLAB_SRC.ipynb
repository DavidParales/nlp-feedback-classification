{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7b5f4ec",
   "metadata": {},
   "source": [
    "# NLP Feedback Modeling Framework (NLP + Survey Analytics) — **Colab-ready + src modular**\n",
    "**Autor:** David José Parales Araujo  \n",
    "\n",
    "Este notebook está preparado para ejecutarse en **Google Colab** sin romper nada:\n",
    "\n",
    "✅ Si `src/` **no existe**, lo crea automáticamente (módulos: preprocessing/targets/modeling/analytics).  \n",
    "✅ Si ejecutas desde tu repo clonado, también funciona (solo reutiliza `src/`).  \n",
    "\n",
    "Incluye:\n",
    "- Índice 0–100 desde Likert\n",
    "- Clasificación binaria + multiclase\n",
    "- Desbalance (class_weight + threshold tuning + SMOTE opcional)\n",
    "- Agregaciones listas para Power BI / Looker\n",
    "- Interpretabilidad (top tokens por clase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3261d10e",
   "metadata": {},
   "source": [
    "## 1) Install & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e806fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Colab: instalar dependencias (silencioso) ---\n",
    "!pip -q install pandas numpy scikit-learn nltk matplotlib joblib imbalanced-learn\n",
    "\n",
    "import os, sys, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import (\n",
    "    classification_report, ConfusionMatrixDisplay,\n",
    "    f1_score\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "nltk.download(\"stopwords\", quiet=True)\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c81e9ed",
   "metadata": {},
   "source": [
    "## 2) Ensure `src/` modules exist (auto-create if missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da9bda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si estás ejecutando este notebook suelto en Colab, no tendrás la carpeta src/.\n",
    "# Este bloque la crea automáticamente para que el notebook sea 100% ejecutable.\n",
    "\n",
    "os.makedirs(\"src\", exist_ok=True)\n",
    "\n",
    "preprocessing_py = r'''\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "nltk.download(\"stopwords\", quiet=True)\n",
    "\n",
    "STOPWORDS_ES = set(stopwords.words(\"spanish\"))\n",
    "\n",
    "def preprocess_text(text: str) -> str:\n",
    "    text = (text or \"\").lower()\n",
    "    text = re.sub(r\"[^a-záéíóúñü\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    tokens = word_tokenize(text, language=\"spanish\")\n",
    "    tokens = [t for t in tokens if t not in STOPWORDS_ES and len(t) > 2]\n",
    "    return \" \".join(tokens)\n",
    "'''\n",
    "\n",
    "targets_py = r'''\n",
    "def performance_index_from_likert(likert_avg: float) -> int:\n",
    "    return int(round(likert_avg * 100))\n",
    "\n",
    "def multiclass_from_index(idx: int) -> str:\n",
    "    if idx < 50:\n",
    "        return \"Negativa\"\n",
    "    if idx <= 75:\n",
    "        return \"Neutral\"\n",
    "    return \"Positiva\"\n",
    "\n",
    "def binary_from_index(idx: int, thr_ok: int = 60) -> int:\n",
    "    return int(idx >= thr_ok)\n",
    "'''\n",
    "\n",
    "modeling_py = r'''\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def make_binary_lr(seed: int = 42):\n",
    "    return Pipeline([\n",
    "        (\"tfidf\", TfidfVectorizer(ngram_range=(1, 2), max_features=5000)),\n",
    "        (\"clf\", LogisticRegression(max_iter=2000, class_weight=\"balanced\", random_state=seed)),\n",
    "    ])\n",
    "\n",
    "def make_binary_svm(seed: int = 42):\n",
    "    return Pipeline([\n",
    "        (\"tfidf\", TfidfVectorizer(ngram_range=(1, 2), max_features=5000)),\n",
    "        (\"clf\", LinearSVC(class_weight=\"balanced\", random_state=seed)),\n",
    "    ])\n",
    "\n",
    "def best_threshold(y_true, prob_pos, thresholds=None):\n",
    "    if thresholds is None:\n",
    "        thresholds = np.linspace(0.2, 0.8, 13)\n",
    "    best_thr, best_f1 = None, -1.0\n",
    "    for thr in thresholds:\n",
    "        pred = (prob_pos >= thr).astype(int)\n",
    "        f1 = f1_score(y_true, pred, average=\"macro\")\n",
    "        if f1 > best_f1:\n",
    "            best_thr, best_f1 = float(thr), float(f1)\n",
    "    return best_thr, best_f1\n",
    "'''\n",
    "\n",
    "analytics_py = r'''\n",
    "import numpy as np\n",
    "\n",
    "def composite_index(likert_avg, prob_ok_text, w_likert: float = 0.6, w_text: float = 0.4) -> int:\n",
    "    score = (w_likert * likert_avg + w_text * prob_ok_text) * 100\n",
    "    return int(round(score))\n",
    "\n",
    "def make_aggregations(df):\n",
    "    return (df.groupby([\"year\", \"level\", \"role_evaluator\"], as_index=False)\n",
    "            .agg(\n",
    "                n=(\"text_feedback\", \"count\"),\n",
    "                index_mean=(\"performance_index_composite\", \"mean\"),\n",
    "                index_p25=(\"performance_index_composite\", lambda x: np.percentile(x, 25)),\n",
    "                index_p75=(\"performance_index_composite\", lambda x: np.percentile(x, 75)),\n",
    "            ))\n",
    "'''\n",
    "\n",
    "files = {\n",
    "    \"src/preprocessing.py\": preprocessing_py,\n",
    "    \"src/targets.py\": targets_py,\n",
    "    \"src/modeling.py\": modeling_py,\n",
    "    \"src/analytics.py\": analytics_py,\n",
    "    \"src/__init__.py\": \"\"\n",
    "}\n",
    "\n",
    "for path, content in files.items():\n",
    "    if not os.path.exists(path) or os.path.getsize(path) == 0:\n",
    "        with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(content.strip() + \"\\n\")\n",
    "\n",
    "sys.path.append(os.path.abspath(\".\"))\n",
    "\n",
    "from src.preprocessing import preprocess_text\n",
    "from src.targets import performance_index_from_likert, multiclass_from_index, binary_from_index\n",
    "from src.modeling import make_binary_lr, make_binary_svm, best_threshold\n",
    "from src.analytics import composite_index, make_aggregations\n",
    "\n",
    "print(\"✅ src/ listo e importado correctamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d111e0",
   "metadata": {},
   "source": [
    "## 3) Load data (sample) — replace with your anonymized CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a8b5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplaza por: df = pd.read_csv(\"data/tu_archivo.csv\")\n",
    "\n",
    "positive_texts = [\n",
    "    \"Explica con claridad y responde dudas con paciencia.\",\n",
    "    \"Las clases son dinámicas y se nota dominio del tema.\",\n",
    "    \"Motiva al curso y brinda material útil.\",\n",
    "    \"Evalúa de forma justa y retroalimenta con detalle.\"\n",
    "]\n",
    "neutral_texts = [\n",
    "    \"Algunas clases son buenas, otras podrían mejorar.\",\n",
    "    \"A veces explica claro, a veces rápido.\",\n",
    "    \"El ritmo es variable, en general cumple.\"\n",
    "]\n",
    "negative_texts = [\n",
    "    \"Las explicaciones son confusas y desorganizadas.\",\n",
    "    \"No responde bien a las preguntas y llega tarde.\",\n",
    "    \"Las clases son aburridas y poco productivas.\",\n",
    "    \"Las evaluaciones no reflejan lo visto en clase.\"\n",
    "]\n",
    "\n",
    "def make_rows(n=900, p_pos=0.65, p_neu=0.20, p_neg=0.15):\n",
    "    rows = []\n",
    "    for _ in range(n):\n",
    "        r = np.random.rand()\n",
    "        if r < p_neg:\n",
    "            txt = np.random.choice(negative_texts)\n",
    "            likert = np.random.uniform(0.15, 0.55)\n",
    "        elif r < p_neg + p_neu:\n",
    "            txt = np.random.choice(neutral_texts)\n",
    "            likert = np.random.uniform(0.45, 0.75)\n",
    "        else:\n",
    "            txt = np.random.choice(positive_texts)\n",
    "            likert = np.random.uniform(0.65, 0.95)\n",
    "\n",
    "        source = np.random.choice([\"student\", \"leadership\", \"self\"], p=[0.7, 0.2, 0.1])\n",
    "        role = {\"student\":\"student\", \"leadership\":\"director\", \"self\":\"self\"}[source]\n",
    "        year = np.random.choice([2023, 2024, 2025])\n",
    "        level = np.random.choice([1,2,3,4,5])\n",
    "        rows.append([source, year, level, role, float(likert), txt])\n",
    "\n",
    "    return pd.DataFrame(rows, columns=[\"source\",\"year\",\"level\",\"role_evaluator\",\"likert_avg\",\"text_feedback\"])\n",
    "\n",
    "df = make_rows()\n",
    "df[\"text_clean\"] = df[\"text_feedback\"].apply(preprocess_text)\n",
    "\n",
    "# Targets derivados desde Likert (evita leakage)\n",
    "df[\"performance_index\"] = df[\"likert_avg\"].apply(performance_index_from_likert)\n",
    "df[\"target_multiclass\"] = df[\"performance_index\"].apply(multiclass_from_index)\n",
    "df[\"target_binary\"] = df[\"performance_index\"].apply(binary_from_index)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c10191d",
   "metadata": {},
   "source": [
    "## 4) Binary classification (Risk vs OK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9819c9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"text_clean\"].values\n",
    "y_bin = df[\"target_binary\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_bin, test_size=0.2, random_state=SEED, stratify=y_bin\n",
    ")\n",
    "\n",
    "binary_lr = make_binary_lr(seed=SEED)\n",
    "binary_svm = make_binary_svm(seed=SEED)\n",
    "\n",
    "binary_lr.fit(X_train, y_train)\n",
    "pred_lr = binary_lr.predict(X_test)\n",
    "\n",
    "binary_svm.fit(X_train, y_train)\n",
    "pred_svm = binary_svm.predict(X_test)\n",
    "\n",
    "print(\"=== Logistic Regression (Binary) ===\")\n",
    "print(classification_report(y_test, pred_lr, target_names=[\"risk(0)\",\"ok(1)\"]))\n",
    "\n",
    "print(\"=== Linear SVM (Binary) ===\")\n",
    "print(classification_report(y_test, pred_svm, target_names=[\"risk(0)\",\"ok(1)\"]))\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, pred_lr, display_labels=[\"risk\",\"ok\"])\n",
    "plt.title(\"Binary - Logistic Regression\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e113ae",
   "metadata": {},
   "source": [
    "## 5) Cross-validation + Threshold tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39f6fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "scores = cross_val_score(binary_lr, X, y_bin, cv=cv, scoring=\"f1_macro\")\n",
    "print(\"Macro F1 (5-fold):\", round(scores.mean(), 4), \"+/-\", round(scores.std(), 4))\n",
    "\n",
    "proba = binary_lr.predict_proba(X_test)[:, 1]\n",
    "thr, f1 = best_threshold(y_test, proba)\n",
    "print(\"Best threshold:\", thr, \"Macro F1:\", round(f1, 4))\n",
    "\n",
    "pred_thr = (proba >= thr).astype(int)\n",
    "print(classification_report(y_test, pred_thr, target_names=[\"risk(0)\",\"ok(1)\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97990fd1",
   "metadata": {},
   "source": [
    "## 6) Multiclass classification (Negativa / Neutral / Positiva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9b4532",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_multi = df[\"target_multiclass\"].values\n",
    "Xm_train, Xm_test, ym_train, ym_test = train_test_split(\n",
    "    X, y_multi, test_size=0.2, random_state=SEED, stratify=y_multi\n",
    ")\n",
    "\n",
    "multi_lr = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(ngram_range=(1,2), max_features=8000)),\n",
    "    (\"clf\", LogisticRegression(max_iter=3000, class_weight=\"balanced\", random_state=SEED))\n",
    "])\n",
    "\n",
    "multi_lr.fit(Xm_train, ym_train)\n",
    "pred_m = multi_lr.predict(Xm_test)\n",
    "\n",
    "print(classification_report(ym_test, pred_m))\n",
    "ConfusionMatrixDisplay.from_predictions(ym_test, pred_m, xticks_rotation=45)\n",
    "plt.title(\"Multiclass - Logistic Regression\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57438a4",
   "metadata": {},
   "source": [
    "## 7) Optional SMOTE (oversampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d27a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    smote_ok = True\n",
    "except Exception:\n",
    "    smote_ok = False\n",
    "\n",
    "if smote_ok:\n",
    "    vec = TfidfVectorizer(ngram_range=(1,2), max_features=5000)\n",
    "    Xv = vec.fit_transform(X_train)\n",
    "    sm = SMOTE(random_state=SEED)\n",
    "    X_res, y_res = sm.fit_resample(Xv, y_train)\n",
    "    clf = LogisticRegression(max_iter=2000, random_state=SEED)\n",
    "    clf.fit(X_res, y_res)\n",
    "\n",
    "    Xt = vec.transform(X_test)\n",
    "    pred = clf.predict(Xt)\n",
    "    print(classification_report(y_test, pred, target_names=[\"risk(0)\",\"ok(1)\"]))\n",
    "else:\n",
    "    print(\"SMOTE no disponible.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aba98fa",
   "metadata": {},
   "source": [
    "## 8) Composite Performance Index (0–100) + Dashboard-ready aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f93db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_ok_text = binary_lr.predict_proba(df[\"text_clean\"])[:, 1]\n",
    "df[\"performance_index_composite\"] = [\n",
    "    composite_index(l, p) for l, p in zip(df[\"likert_avg\"], prob_ok_text)\n",
    "]\n",
    "\n",
    "agg = make_aggregations(df)\n",
    "agg.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dbcd2b",
   "metadata": {},
   "source": [
    "## 9) Interpretability — top weighted tokens (Binary LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9d8399",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = binary_lr.named_steps[\"tfidf\"]\n",
    "clf = binary_lr.named_steps[\"clf\"]\n",
    "\n",
    "feature_names = np.array(tfidf.get_feature_names_out())\n",
    "coefs = clf.coef_.ravel()\n",
    "\n",
    "top_ok = feature_names[np.argsort(coefs)[-15:]][::-1]\n",
    "top_risk = feature_names[np.argsort(coefs)[:15]]\n",
    "\n",
    "print(\"Top tokens que empujan a OK (1):\\n\", top_ok)\n",
    "print(\"\\nTop tokens que empujan a RISK (0):\\n\", top_risk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f654304",
   "metadata": {},
   "source": [
    "## 10) Export outputs (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54032e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg.to_csv(\"dashboard_aggregations.csv\", index=False, encoding=\"utf-8\")\n",
    "df[[\"source\",\"year\",\"level\",\"role_evaluator\",\"likert_avg\",\"performance_index_composite\",\"target_binary\",\"target_multiclass\",\"text_feedback\"]]\\\n",
    "  .to_csv(\"row_level_scored_feedback.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"✅ Exportados: dashboard_aggregations.csv y row_level_scored_feedback.csv\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}